{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal para simulacion de EDOs de primer ordel del tipo\n",
    "$$\\dfrac{d}{dt}S(t)=P_1(t) + P_2(t)*P_3(S)$$\n",
    "donde $P_1$, $P_2$ y $P_3$ son polinomios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('datos_ODEs_100.csv', sep=';')\n",
    "data['sol.t'] = data['sol.t'].apply(lambda x: np.float_(x.replace('[','').replace(']','').split(',')))\n",
    "data['sol.y'] = data['sol.y'].apply(lambda x: np.float_(x.replace('[','').replace(']','').split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funcion</th>\n",
       "      <th>grade_f_t</th>\n",
       "      <th>grade_f_s</th>\n",
       "      <th>I_c</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>int_0</th>\n",
       "      <th>int_f</th>\n",
       "      <th>sol.t</th>\n",
       "      <th>sol.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.006233</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.006232794500511618, -0.006232115111548313,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.316461</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.31646085159362025, -0.31647627524919986, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.130932</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.13093180783284297, -0.13113714783213906, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.989092</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[0.9890922891660388, 0.9887201261693856, 0.987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.577529</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.5775285067922307, -0.5775302944979106, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      funcion  grade_f_t  grade_f_s       I_c  n_steps  int_0  int_f  \\\n",
       "0  polinom_st          6          7 -0.006233      100      0      1   \n",
       "1   polinom_s          0          9 -0.316461      100      0      1   \n",
       "2   polinom_s          0          7 -0.130932      100      0      1   \n",
       "3   polinom_s          0          8  0.989092      100      0      1   \n",
       "4  polinom_st          7          5 -0.577529      100      0      1   \n",
       "\n",
       "                                               sol.t  \\\n",
       "0  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "1  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "2  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "3  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "4  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "\n",
       "                                               sol.y  \n",
       "0  [-0.006232794500511618, -0.006232115111548313,...  \n",
       "1  [-0.31646085159362025, -0.31647627524919986, -...  \n",
       "2  [-0.13093180783284297, -0.13113714783213906, -...  \n",
       "3  [0.9890922891660388, 0.9887201261693856, 0.987...  \n",
       "4  [-0.5775285067922307, -0.5775302944979106, -0....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamano de los datos de polinomio en S y t es: 400225\n",
      "El tamano de los datos de polinomio en S es    : 299729\n",
      "El tamano de los datos de polinomio en t es    : 300046\n",
      "El numero total de los datos es                : 1000000\n"
     ]
    }
   ],
   "source": [
    "# data[data['I_c']<=0].shape\n",
    "print('El tamano de los datos de polinomio en S y t es: {}'.format(data[data['funcion'] == 'polinom_st'].shape[0]))\n",
    "print('El tamano de los datos de polinomio en S es    : {}'.format(data[data['funcion'] == 'polinom_s'].shape[0]))\n",
    "print('El tamano de los datos de polinomio en t es    : {}'.format(data[data['funcion'] == 'polinom_t'].shape[0]))\n",
    "print('El numero total de los datos es                : {}'.format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funcion</th>\n",
       "      <th>grade_f_t</th>\n",
       "      <th>grade_f_s</th>\n",
       "      <th>I_c</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>int_0</th>\n",
       "      <th>int_f</th>\n",
       "      <th>sol.t</th>\n",
       "      <th>sol.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.204293</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.20429320725494327, -0.20447035694942658, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.384119</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.384119438052138, -0.3841104787679275, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.029274</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[0.029274142132506453, 0.029044863991251987, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.158009</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.15800925856030812, -0.15801147667534682, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.766625</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.7666245346147851, -0.7666263669117123, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>polinom_st</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.787185</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[0.7871845331313854, 0.7871797846131655, 0.787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.473147</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.47314689409962507, -0.4729338336903205, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>polinom_s</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.984528</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.9845283991997598, -0.9836540536563606, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>polinom_t</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.716928</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.7169284057100427, -0.7177332303664455, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>polinom_t</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547327</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[0.5473270833517996, 0.5473410813241688, 0.547...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899999 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           funcion  grade_f_t  grade_f_s       I_c  n_steps  int_0  int_f  \\\n",
       "100001   polinom_s          0          8 -0.204293      100      0      1   \n",
       "100002  polinom_st          8          8 -0.384119      100      0      1   \n",
       "100003   polinom_s          0         10  0.029274      100      0      1   \n",
       "100004  polinom_st          6          7 -0.158009      100      0      1   \n",
       "100005  polinom_st          7         10 -0.766625      100      0      1   \n",
       "...            ...        ...        ...       ...      ...    ...    ...   \n",
       "999995  polinom_st          9         10  0.787185      100      0      1   \n",
       "999996   polinom_s          0         10 -0.473147      100      0      1   \n",
       "999997   polinom_s          0         10 -0.984528      100      0      1   \n",
       "999998   polinom_t         10          0 -0.716928      100      0      1   \n",
       "999999   polinom_t          9          0  0.547327      100      0      1   \n",
       "\n",
       "                                                    sol.t  \\\n",
       "100001  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "100002  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "100003  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "100004  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "100005  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "...                                                   ...   \n",
       "999995  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "999996  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "999997  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "999998  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "999999  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "\n",
       "                                                    sol.y  \n",
       "100001  [-0.20429320725494327, -0.20447035694942658, -...  \n",
       "100002  [-0.384119438052138, -0.3841104787679275, -0.3...  \n",
       "100003  [0.029274142132506453, 0.029044863991251987, 0...  \n",
       "100004  [-0.15800925856030812, -0.15801147667534682, -...  \n",
       "100005  [-0.7666245346147851, -0.7666263669117123, -0....  \n",
       "...                                                   ...  \n",
       "999995  [0.7871845331313854, 0.7871797846131655, 0.787...  \n",
       "999996  [-0.47314689409962507, -0.4729338336903205, -0...  \n",
       "999997  [-0.9845283991997598, -0.9836540536563606, -0....  \n",
       "999998  [-0.7169284057100427, -0.7177332303664455, -0....  \n",
       "999999  [0.5473270833517996, 0.5473410813241688, 0.547...  \n",
       "\n",
       "[899999 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_data_train = 0.75\n",
    "pct_data_val = 0.2\n",
    "shape_data = data.shape[0]\n",
    "data[data.index.values > shape_data*0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las diferentes datas de entrenamiento, de validacion y de prueba\n",
    "pct_data_train = 0.75\n",
    "pct_data_val = 0.2\n",
    "shape_data = data.shape[0]\n",
    "\n",
    "df_train = data[data.index.values <= shape_data*pct_data_train]\n",
    "df_val = data[(data.index.values > shape_data*pct_data_train) & (data.index.values <= shape_data*(pct_data_train+pct_data_val))]\n",
    "df_test = data[data.index.values > shape_data*(pct_data_train + pct_data_val)]\n",
    "\n",
    "df_train_v = df_train.values\n",
    "df_val_v = df_val.values\n",
    "df_test_v = df_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 75\n",
    "len_sim = len(df_train_v[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los datasets de entrenamiento, validacion y prueba\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(seq_len, len(df_train_v)):\n",
    "    tmp = df_train_v[i][8][:seq_len]\n",
    "    X_train.append(tmp)\n",
    "    \n",
    "    tmp = df_train_v[i][8][seq_len:]\n",
    "    Y_train.append(tmp)\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for i in range(seq_len, len(df_val_v)):\n",
    "    tmp = df_val_v[i][8][:seq_len]\n",
    "    X_val.append(tmp)\n",
    "    \n",
    "    tmp = df_val_v[i][8][seq_len:]\n",
    "    Y_val.append(tmp)\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(seq_len, len(df_test_v)):\n",
    "    tmp = df_test_v[i][8][:seq_len]\n",
    "    X_test.append(tmp)\n",
    "    \n",
    "    tmp = df_test_v[i][8][seq_len:]\n",
    "    Y_test.append(tmp)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "\n",
    "X_val = torch.from_numpy(X_val)\n",
    "Y_val = torch.from_numpy(Y_val)\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "Y_test = torch.from_numpy(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configurar bien los datos de entreada y salida\n",
    "configurar las dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Estamos usando: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    \"\"\"\n",
    "    Parametros\n",
    "    ----------\n",
    "    device : torch.device\n",
    "    data_dim : int\n",
    "        Dimension de la data.\n",
    "    hidden_dim : int\n",
    "        Dimension de las capas oculatas.\n",
    "    augment_dim: int\n",
    "        Dimension of augmentacion. Si es 0 no aumenta la EDO, otros argumentos aumentaran la data.\n",
    "    time_dependent : bool\n",
    "        Si es True anade al tiempo como una entrada, haciendo a la EDO dependiente de tiempo.\n",
    "    non_linearity : string\n",
    "        'relu' o 'softplus'\n",
    "    \"\"\"\n",
    "    def __init__(self, device, data_dim, hidden_dim, augment_dim=0,\n",
    "                 time_dependent=False, non_linearity='relu'):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.device = device\n",
    "        self.augment_dim = augment_dim\n",
    "        self.data_dim = data_dim\n",
    "        self.input_dim = data_dim + augment_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nfe = 0  # Numero de evalauciones de funciones\n",
    "        self.time_dependent = time_dependent\n",
    "\n",
    "        if time_dependent:\n",
    "            self.fc1 = nn.Linear(self.input_dim + 1, hidden_dim)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(self.input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, self.input_dim)\n",
    "\n",
    "        if non_linearity == 'relu':\n",
    "            self.non_linearity = nn.ReLU(inplace=True)\n",
    "        elif non_linearity == 'softplus':\n",
    "            self.non_linearity = nn.Softplus()\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        Parametros\n",
    "        ----------\n",
    "        t : torch.Tensor\n",
    "            Tamano del tiempo actual (1,).\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, input_dim)\n",
    "        \"\"\"\n",
    "        # El forward del modelo corresponde a la evaluación de una función, por lo que\n",
    "        # incrementamos el contador\n",
    "        self.nfe += 1\n",
    "        if self.time_dependent:\n",
    "            # Shape (batch_size, 1)\n",
    "            t_vec = torch.ones(x.shape[0], 1).to(self.device) * t\n",
    "            # Shape (batch_size, data_dim + 1)\n",
    "            t_and_x = torch.cat([t_vec, x], 1)\n",
    "            # Shape (batch_size, hidden_dim)\n",
    "            out = self.fc1(t_and_x)\n",
    "        else:\n",
    "            out = self.fc1(x)\n",
    "        out = self.non_linearity(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.non_linearity(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "class ODEBlock(nn.Module):\n",
    "    \"\"\"Resuelve EDOs definidas por odefunc.\n",
    "    Parametros\n",
    "    ----------\n",
    "    device : torch.device\n",
    "    odefunc : ODEFunc instance or anode.conv_models.ConvODEFunc instance\n",
    "        Function defining dynamics of system.\n",
    "    is_conv : bool\n",
    "        If True, treats odefunc as a convolutional model.\n",
    "    tol : float\n",
    "        Error tolerance.\n",
    "    adjoint : bool\n",
    "        If True calculates gradient with adjoint method, otherwise\n",
    "        backpropagates directly through operations of ODE solver.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, odefunc, is_conv=False, tol=1e-3, adjoint=False):\n",
    "        super(ODEBlock, self).__init__()\n",
    "        self.adjoint = adjoint\n",
    "        self.device = device\n",
    "        self.is_conv = is_conv\n",
    "        self.odefunc = odefunc\n",
    "        self.tol = tol\n",
    "\n",
    "    def forward(self, x, eval_times=None):\n",
    "        \"\"\"Solves ODE starting from x.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, self.odefunc.data_dim)\n",
    "        eval_times : None or torch.Tensor\n",
    "            If None, returns solution of ODE at final time t=1. If torch.Tensor\n",
    "            then returns full ODE trajectory evaluated at points in eval_times.\n",
    "        \"\"\"\n",
    "        # Forward pass corresponds to solving ODE, so reset number of function\n",
    "        # evaluations counter\n",
    "        self.odefunc.nfe = 0\n",
    "\n",
    "        if eval_times is None:\n",
    "            integration_time = torch.tensor([0, 1]).float().type_as(x)\n",
    "        else:\n",
    "            integration_time = eval_times.type_as(x)\n",
    "\n",
    "\n",
    "        if self.odefunc.augment_dim > 0:\n",
    "            if self.is_conv:\n",
    "                # Add augmentation\n",
    "                batch_size, channels, height, width = x.shape\n",
    "                aug = torch.zeros(batch_size, self.odefunc.augment_dim,\n",
    "                                  height, width).to(self.device)\n",
    "                # Shape (batch_size, channels + augment_dim, height, width)\n",
    "                x_aug = torch.cat([x, aug], 1)\n",
    "            else:\n",
    "                # Add augmentation\n",
    "                aug = torch.zeros(x.shape[0], self.odefunc.augment_dim).to(self.device)\n",
    "                # Shape (batch_size, data_dim + augment_dim)\n",
    "                x_aug = torch.cat([x, aug], 1)\n",
    "        else:\n",
    "            x_aug = x\n",
    "\n",
    "        if self.adjoint:\n",
    "            out = odeint_adjoint(self.odefunc, x_aug, integration_time,\n",
    "                                 rtol=self.tol, atol=self.tol, method='dopri5',\n",
    "                                 options={'max_num_steps': MAX_NUM_STEPS})\n",
    "        else:\n",
    "            out = odeint(self.odefunc, x_aug, integration_time,\n",
    "                         rtol=self.tol, atol=self.tol, method='dopri5',\n",
    "                         options={'max_num_steps': MAX_NUM_STEPS})\n",
    "\n",
    "        if eval_times is None:\n",
    "            return out[1]  # Return only final time\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def trajectory(self, x, timesteps):\n",
    "        \"\"\"Returns ODE trajectory.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, self.odefunc.data_dim)\n",
    "        timesteps : int\n",
    "            Number of timesteps in trajectory.\n",
    "        \"\"\"\n",
    "        integration_time = torch.linspace(0., 1., timesteps)\n",
    "        return self.forward(x, eval_times=integration_time)\n",
    "\n",
    "\n",
    "class ODENet(nn.Module):\n",
    "    \"\"\"An ODEBlock followed by a Linear layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : torch.device\n",
    "    data_dim : int\n",
    "        Dimension of data.\n",
    "    hidden_dim : int\n",
    "        Dimension of hidden layers.\n",
    "    output_dim : int\n",
    "        Dimension of output after hidden layer. Should be 1 for regression or\n",
    "        num_classes for classification.\n",
    "    augment_dim: int\n",
    "        Dimension of augmentation. If 0 does not augment ODE, otherwise augments\n",
    "        it with augment_dim dimensions.\n",
    "    time_dependent : bool\n",
    "        If True adds time as input, making ODE time dependent.\n",
    "    non_linearity : string\n",
    "        One of 'relu' and 'softplus'\n",
    "    tol : float\n",
    "        Error tolerance.\n",
    "    adjoint : bool\n",
    "        If True calculates gradient with adjoint method, otherwise\n",
    "        backpropagates directly through operations of ODE solver.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, data_dim, hidden_dim, output_dim=1,\n",
    "                 augment_dim=0, time_dependent=False, non_linearity='relu',\n",
    "                 tol=1e-3, adjoint=False):\n",
    "        super(ODENet, self).__init__()\n",
    "        self.device = device\n",
    "        self.data_dim = data_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.augment_dim = augment_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.time_dependent = time_dependent\n",
    "        self.tol = tol\n",
    "\n",
    "        odefunc = ODEFunc(device, data_dim, hidden_dim, augment_dim,\n",
    "                          time_dependent, non_linearity)\n",
    "\n",
    "        self.odeblock = ODEBlock(device, odefunc, tol=tol, adjoint=adjoint)\n",
    "        self.linear_layer = nn.Linear(self.odeblock.odefunc.input_dim,\n",
    "                                      self.output_dim)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        features = self.odeblock(x)\n",
    "        pred = self.linear_layer(features)\n",
    "        if return_features:\n",
    "            return features, pred\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "n_hidden = 128\n",
    "model = RNN(input_size = seq_len, hidden_size = n_hidden, output_size = len_sim-seq_len)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando: cuda\n"
     ]
    }
   ],
   "source": [
    "print('Estamos usando: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            26,112\n",
      "├─Linear: 1-2                            5,100\n",
      "├─LogSoftmax: 1-3                        --\n",
      "=================================================================\n",
      "Total params: 31,212\n",
      "Trainable params: 31,212\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Linear: 1-1                            26,112\n",
       "├─Linear: 1-2                            5,100\n",
       "├─LogSoftmax: 1-3                        --\n",
       "=================================================================\n",
       "Total params: 31,212\n",
       "Trainable params: 31,212\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros\n",
    "batch_size = 4\n",
    "seq_len = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "hidden = n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNN.forward() missing 1 required positional argument: 'hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m batch_x, batch_y \u001b[39m=\u001b[39m X_train[indices], Y_train[indices]\n\u001b[0;32m     14\u001b[0m \u001b[39m# outputs = model.forward(batch_x)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs, hidden \u001b[39m=\u001b[39m model(batch_x)\n\u001b[0;32m     16\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, batch_y)\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: RNN.forward() missing 1 required positional argument: 'hidden'"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # permutamos la data de entrenamiento\n",
    "    permutation = torch.randperm(X_train.size()[0])\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(0, X_train.size()[0], batch_size):\n",
    "        # inicializamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = X_train[indices], Y_train[indices]\n",
    "        \n",
    "        # outputs = model.forward(batch_x)\n",
    "        outputs, hidden = model(batch_x)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss_epoch =  running_loss / float(len(X_train))\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss_epoch))\n",
    "#                 running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55bc0a9a8bb0a63da52a83eb35b0d87a27a1e6148b28f04c025814529ba0e733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
